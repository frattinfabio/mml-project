{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of tree and SVM based ensemble classification techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./spambase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows containing null values\n",
    "print(\"Dataset length before dropping null values: \", len(df))\n",
    "df.dropna(inplace = True)\n",
    "print(\"Dataset length after dropping null values: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping outliers with a z-score analysis on \n",
    "print(\"Dataset length before dropping outliers: \", len(df))\n",
    "z_scores = stats.zscore(df[[\"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\"]])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <= 3).all(axis=1)\n",
    "df = df[filtered_entries]\n",
    "print(\"Dataset length after dropping outlierss: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping too much specific features\n",
    "df = df.drop([\"word_freq_george\", \"word_freq_650\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing the correlation between attributes and dropping highly (>=0.7) correlated features\n",
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] >= 0.7)]\n",
    "print(\"Features to drop:\", to_drop)\n",
    "df = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"is_spam\"]\n",
    "df = df.drop([\"is_spam\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data visualization: KDE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = df.loc[target == 1]\n",
    "no_spam_df = df.loc[target == 0]\n",
    "\n",
    "def kde_plot(feature_name):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.kdeplot(spam_df[feature_name], color='r', shade=True, Label= 'spam') \n",
    "    sns.kdeplot(no_spam_df[feature_name], color='b', shade=True, Label= 'no_spam') \n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.xlabel(feature_name, fontsize = 15) \n",
    "    plt.ylabel('Probability Density', fontsize = 15)\n",
    "\n",
    "for label in df.columns.values:\n",
    "    kde_plot(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram class count plot\n",
    "vc = target.value_counts().sort_index()\n",
    "vc.index = [\"no_spam\", \"spam\"]\n",
    "ax = vc.plot(kind = 'bar', rot = 0)\n",
    "ax.set_ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data pre-processing: Standardization and dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to split data into trai and test before making any pre-processing activity: fit only on train data and only transform test data \n",
    "X = df.values\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing subtracting mean and dividing by the variance for each column\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA dimensionality reduction\n",
    "\n",
    "def compute_PCA(X, cum_var_tresh = 0.8):\n",
    "    \n",
    "    pca = PCA().fit(X_train)\n",
    "    var_exp = pca.explained_variance_ratio_\n",
    "    cum_var_exp = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_comp = np.where(cum_var_exp >= cum_var_tresh)[0][0]\n",
    "    x = list(range(1, len(var_exp)+ 1))\n",
    "\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[1, 2]) \n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    line0, = ax0.plot(x, var_exp, color='r')\n",
    "\n",
    "    ax1 = plt.subplot(gs[1], sharex = ax0)\n",
    "    line1, = ax1.plot(x, cum_var_exp, color='g', linestyle='--')\n",
    "\n",
    "    ax0.axvline(n_comp, linestyle = \":\")\n",
    "    ax1.axvline(n_comp, linestyle = \":\")\n",
    "    ax1.axhline(cum_var_tresh, 0, n_comp/len(var_exp), linestyle = \":\")\n",
    "\n",
    "    ax0.legend((line0, line1), ('variance explained', 'cumulative variance explained'), loc='upper right')\n",
    "    ax0.set_ylabel(\"variance explained\")\n",
    "    ax1.set_xlabel(\"number of components\")\n",
    "    ax1.set_ylabel(\"cumulative variance\")\n",
    "\n",
    "    plt.subplots_adjust(hspace=.0)\n",
    "    plt.show()\n",
    "    \n",
    "    return n_comp\n",
    "\n",
    "cum_var_treshold = 0.7\n",
    "n_components = compute_PCA(X_train, cum_var_treshold)\n",
    "print(f\"To explain the {cum_var_treshold*100:.2f}% of the total variance we need {n_components} components.\")\n",
    "\n",
    "pca = PCA(n_components = n_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train\n",
    "test = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tree_results = pd.DataFrame(columns = [\"max_depth\", \"tree\", \"bagging\", \"forest\", \"boosting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the different methods varying the maximum depth\n",
    "\n",
    "depths = [1, 5, 10, 20, None]\n",
    "\n",
    "for depth in depths:\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth = depth, random_state = 42)\n",
    "    bag = BaggingClassifier(base_estimator = tree, n_estimators = 50, random_state = 42)\n",
    "    forest = RandomForestClassifier(max_depth = depth, n_estimators = 50, random_state = 42)\n",
    "    boost = AdaBoostClassifier(base_estimator = tree, n_estimators = 50, random_state = 42)\n",
    "    \n",
    "    clfs = {\n",
    "                \"tree\": tree,\n",
    "                \"bagging\" : bag,\n",
    "                \"forest\": forest,\n",
    "                \"boosting\": boost\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        \"max_depth\": depth if depth is not None else \"inf\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for k in clfs.keys():\n",
    "        \n",
    "#         print(f\"Classifier {k} with max depth {depth}.\")\n",
    "        clf = clfs[k]\n",
    "        clf.fit(train, y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "#         print(f\"Train accuracy: {acc:.2f}\")\n",
    "        results[k] = acc\n",
    "#         print(\"\")\n",
    "        \n",
    "    df_tree_results = df_tree_results.append(results, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results\n",
    "\n",
    "df_tree_results.set_index(\"max_depth\")\n",
    "\n",
    "styles = ['bP--', 'ro-', 'y^-', 'gs-']\n",
    "lws = [2, 3, 3, 3]\n",
    "\n",
    "ax = df_tree_results.plot(x = \"max_depth\", figsize = (14, 10), ylim = (0.6,1.1), style = styles, markersize = 12)\n",
    "for i, l in enumerate(ax.lines):\n",
    "    plt.setp(l, linewidth=lws[i])\n",
    "             \n",
    "plt.legend(loc=\"lower right\", fontsize = 18)\n",
    "plt.xlabel(\"Tree maximum depth\", fontsize = 18)\n",
    "plt.ylabel(\"Accuracy score\",  fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm_results = pd.DataFrame(columns = [\"C\", \"svm\", \"bagging\", \"boosting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing th different methods varying the value of the penalty\n",
    "\n",
    "C_values = [0.1, 0.5, 1, 10]\n",
    "\n",
    "for C in C_values:\n",
    "    \n",
    "    svm = LinearSVC(C = C, random_state = 42, max_iterations = 10000)\n",
    "    bag = BaggingClassifier(base_estimator = svm, n_estimators = 50, max_samples = 0.5, random_state = 42)\n",
    "    boost = AdaBoostClassifier(base_estimator = svm, n_estimators = 50, random_state = 42, algorithm = \"SAMME\")\n",
    "    \n",
    "    clfs = {\n",
    "                \"svm\": svm,\n",
    "                \"bagging\" : bag,\n",
    "                \"boosting\": boost\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        \"C\": str(C)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for k in clfs.keys():\n",
    "        \n",
    "#         print(f\"Classifier {k} with C {C}.\")\n",
    "        clf = clfs[k]\n",
    "        clf.fit(train, y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "#         print(f\"Test accuracy: {acc:.2f}\")\n",
    "        results[k] = acc\n",
    "#         print(\"\")\n",
    "        \n",
    "    df_svm_results = df_svm_results.append(results, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "df_svm_results.set_index(\"C\")\n",
    "\n",
    "styles = ['bP--', 'ro-', 'gs-']\n",
    "lws = [2, 3, 3]\n",
    "\n",
    "ax = df_svm_results.plot(x = \"C\", figsize = (14, 10), ylim = (0.8,1), style = styles, markersize = 12)\n",
    "for i, l in enumerate(ax.lines):\n",
    "    plt.setp(l, linewidth=lws[i])\n",
    "             \n",
    "plt.legend(loc=\"lower right\", fontsize = 18)\n",
    "plt.xlabel(\"C\", fontsize = 18)\n",
    "plt.ylabel(\"Accuracy score\",  fontsize = 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
